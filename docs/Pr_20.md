
# –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ20 –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤

---

## üéØ –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã.

–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –∏–Ω—ã—Ö –≤–∏–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Ç–∏–ø–∞ Transformer

## üìö –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Ä–∞–±–æ—Ç–µ

  - –í–∞—Ä–∏–∞–Ω—Ç 1. –ò–∑—É—á–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ –ª–µ–∫—Ü–∏–π –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
  - –í–∞—Ä–∏–∞–Ω—Ç 2. –û–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: [—Å—Å—ã–ª–∫–∞ 1](https://huggingface.co/learn/llm-course/ru/chapter1/3), [—Å—Å—ã–ª–∫–∞ 2](https://habr.com/ru/companies/wunderfund/articles/593713/) –∏ —Ç.–¥.

---

## üìÅ –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –º–µ—Ç–æ–¥—ã

- –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ - [Ubuntu 22.04](https://help.ubuntu.ru/wiki/–∫–æ–º–∞–Ω–¥–Ω–∞—è_—Å—Ç—Ä–æ–∫–∞)
- –Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äì [python](https://www.python.org/).
- –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:
  -  [jupyter Notebook](https://jupyter.org/).
- –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
  - [matplotlib](https://matplotlib.org/)
  - [numpy](https://numpy.org/)
  - [PyTorch](https://pytorch.org/get-started/locally/)
  - [transformers](https://huggingface.co/docs/transformers/index)
  - [datasets](https://huggingface.co/docs/datasets/index)

---

## üß™ –ü—Ä–æ–≥—Ä–∞–º–º–∞ —Ä–∞–±–æ—Ç—ã 

---

### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã  

**–ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ [Jupyter-Hub](https://jupyter.org/hub) –ø–æ –∞–¥—Ä–µ—Å—É [Jupyter-Hub-–ò–ò–°–¢-–ù–ü–ò](http://195.133.13.56:8000/)**

![–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è](https://github.com/danil1online/intelligent_information_and_measurement_systems/blob/main/images/autorization.png)

**–° –ø–æ–º–æ—â—å—é —Ñ–∞–π–ª–æ–≤–æ–≥–æ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä–∞, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–ª–µ–≤–∞ –ø–µ—Ä–µ–π—Ç–∏ –≤ —Å–≤–æ–π –∫–∞—Ç–∞–ª–æ–≥ (–§–ò–û –∏ –≥–æ–¥), —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ä–∞–Ω–µ–µ (–¥–≤–æ–π–Ω—ã–º –Ω–∞–∂–∞—Ç–∏–µ–º –º—ã—à–∏)**

![–ü–µ—Ä–µ—Ö–æ–¥ –≤ –∫–∞—Ç–∞–ª–æ–≥](../images/work_dir.png)

**–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –≤–∫–ª–∞–¥–∫—É —Å–∏–º–≤–æ–ª–æ–º +**

![–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–∏](https://github.com/danil1online/intelligent_information_and_measurement_systems/blob/main/images/new_window_create.png)

**–í—ã–±—Ä–∞—Ç—å —Ç–∏–ø –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–∏ -- Notebook**

![–°–æ–∑–¥–∞–Ω–∏–µ –≤–∫–ª–∞–¥–∫–∏ Notebook](../images/notebook.png)

**–°–æ—Ö—Ä–∞–Ω–∏—Ç—å / –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Ñ–∞–π–ª**

![–°–æ–∑–¥–∞–Ω–∏–µ –≤–∫–ª–∞–¥–∫–∏ Notebook](../images/save_new_file.png)

**–†–∞–±–æ—Ç–∞—Ç—å –≤ –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–µ –≤–∏–¥–∞**

![–í–ª–∞–¥–∫–∞ Notebook](../images/notebook_clear_window.png)

**–ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫**

```python
from datasets import load_dataset
from transformers import pipeline
import pandas as pd
from pathlib import Path
import time
cache_path_str = "/home/jupyter/work/cache_huggingface"
cache_path = Path(cache_path_str)
from IPython.display import HTML, display
```

---

### üß™ –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤

  1. üß™ –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
–û–±–æ–±—â–µ–Ω–∏–µ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –¥–≤–µ —Ñ–æ—Ä–º—ã:

extractive(–≤—ã–±–æ—Ä —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç—Ä—ã–≤–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞)
abstractive(–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—Ñ–µ—Ä–∞—Ç–æ–≤ –Ω–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤) –ó–¥–µ—Å—å –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ–µ —Ä–µ—Ñ–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è : –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∑–∞–¥–∞–Ω–∏—è –ø–æ —Ä–µ—Ñ–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—é Hugging Face –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–µ–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ —Ä–µ—Ñ–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ. –ì–ª–∞–≤–∞ –∫—É—Ä—Å–∞, –ø–æ—Å–≤—è—â—ë–Ω–Ω–∞—è —Ä–µ—Ñ–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—é, —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–µ –ø–æ—à–∞–≥–æ–≤–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ. –í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
–î–∞–Ω–Ω—ã–µ : –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö xsum , —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –Ω–∞–±–æ—Ä —Å—Ç–∞—Ç–µ–π –∏ —Ä–µ–∑—é–º–µ BBC.
–ú–æ–¥–µ–ª—å : t5-small , —Å–æ–¥–µ—Ä–∂–∞—â–∞—è 60 –º–∏–ª–ª–∏–æ–Ω–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (242 –ú–ë –¥–ª—è PyTorch). T5 ‚Äî —ç—Ç–æ –º–æ–¥–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞-–¥–µ–∫–æ–¥–µ—Ä–∞, —Å–æ–∑–¥–∞–Ω–Ω–∞—è Google, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—è–¥ –∑–∞–¥–∞—á, —Ç–∞–∫–∏—Ö –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø–µ—Ä–µ–≤–æ–¥, –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞. –ü–æ–¥—Ä–æ–±–Ω–µ–µ —Å–º. –≤ –±–ª–æ–≥–µ Google , –∫–æ–¥–µ –Ω–∞ GitHub –∏–ª–∏ –≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Å—Ç–∞—Ç—å–µ .
```python
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 4

trainset = torchvision.datasets.CIFAR10(root='/home/jupyter/work/data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='/home/jupyter/work/data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```
  2. üß™ –ü—Ä–æ—Å–º–æ—Ç—Ä–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —É—á–µ–±–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
```python
import matplotlib.pyplot as plt
import numpy as np

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(trainloader)
images, labels = next(dataiter)

imshow(torchvision.utils.make_grid(images))
print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))
```
  3. üß™ –û–ø—Ä–µ–¥–µ–ª–∏–º —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
```python
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super().__init__()
        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html
        self.conv1 = nn.Conv2d(3, 6, 5)
        # https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        # Flattens the output of a multi-dimensional volume (e.g., a CONV or POOL layer) such that we can apply fully connected layers to it
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
device = torch.device('cpu')
net.to(device)
```
  4. üß™ –û–ø—Ä–µ–¥–µ–ª–∏–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
```python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```
  5. üß™ –û–±—É—á–∞–µ–º —Å–µ—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏–º –Ω–∞—à—É –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
```python
for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0

print('Finished Training')
PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)
```
  6. üß™ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
```python
# –ü—Ä–µ–¥—Å–∫–∞–∂–µ–º –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞, –∫–æ—Ç–æ—Ä—É—é –≤—ã–¥–∞—Å—Ç –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å, –∏ —Å–≤–µ—Ä–∏–º –µ—ë —Å –∏—Å—Ç–∏–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º.
‚Ññ –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–Ω–æ, –º—ã –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–∑–µ—Ü –≤ —Å–ø–∏—Å–æ–∫ –≤–µ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
dataiter = iter(testloader)
images, labels = next(dataiter)

# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))

# –ó–∞–≥—Ä—É–∑–∏–º –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞—à—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
# (–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∑–¥–µ—Å—å –Ω–µ –±—ã–ª–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏, –º—ã —Å–¥–µ–ª–∞–ª–∏ —ç—Ç–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø—Ä–æ–∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å, –∫–∞–∫ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å)
net = Net()
net.load_state_dict(torch.load(PATH, weights_only=True))

# –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –¥—É–º–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –æ–± —ç—Ç–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
outputs = net(images)

# –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è 10 –∫–ª–∞—Å—Å–æ–≤.
# –ß–µ–º –≤—ã—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞, —Ç–µ–º –±–æ–ª—å—à–µ —Å–µ—Ç—å —Å–∫–ª–æ–Ω–Ω–∞ —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç —ç—Ç–æ–º—É –∫–ª–∞—Å—Å—É.
# –ü–æ–ª—É—á–∏–º –∏–Ω–¥–µ–∫—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–µ–π:

_, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'
                              for j in range(4)))

# –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Å–µ—Ç—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–æ –≤—Å–µ–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö
correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in testloader:
        images, labels = data
        # calculate outputs by running images through the network
        outputs = net(images)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')

# —Ç–æ–∂–µ —Å–∞–º–æ–µ, –Ω–æ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
correct_pred = {classname: 0 for classname in classes}
total_pred = {classname: 0 for classname in classes}

with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predictions = torch.max(outputs, 1)
        # collect the correct predictions for each class
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1

for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')
```

--- 

### üìå –ó–∞–¥–∞–Ω–∏—è

  - –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –Ω–∞ **1** _—à–∏—Ä–∏–Ω—É_ –≤–∞—à–µ–π —Å–µ—Ç–∏ (–∞—Ä–≥—É–º–µ–Ω—Ç ‚Ññ2 –ø–µ—Ä–≤–æ–≥–æ nn.Conv2d –∏ –∞—Ä–≥—É–º–µ–Ω—Ç ‚Ññ1 –≤—Ç–æ—Ä–æ–≥–æ nn.Conv2d ‚Äî –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ —á–∏—Å–ª–∞–º–∏) –∏ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ, –∫–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—Å—è —Ç–æ—á–Ω–æ—Å—Ç—å.

### üìå –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç—á–µ—Ç –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–º –ó–∞–¥–∞–Ω–∏–∏

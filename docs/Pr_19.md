# –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ19 –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

---

## üéØ –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã.

–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π (CNN)

## üìö –û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏ –∏ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã.

–°—É—Ç—å –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Ä–∞–Ω–µ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞–±–æ—Ç. –û—Å–Ω–æ–≤–Ω–æ–µ –æ—Ç–ª–∏—á–∏–µ - –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏. 
–ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, —Ç–µ–∫—Å—Ç–æ–º, –∞—É–¥–∏–æ- –∏–ª–∏ –≤–∏–¥–µ–æ–¥–∞–Ω–Ω—ã–º–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [—Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏](https://habr.com/ru/companies/skillfactory/articles/823516/) –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞–∫–µ—Ç—ã Python, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç –¥–∞–Ω–Ω—ã–µ –≤ –º–∞—Å—Å–∏–≤ numpy. –ó–∞—Ç–µ–º, –µ—Å–ª–∏, –∫–∞–∫ –≤ –¥–∞–Ω–Ω–æ–π —Ä–∞–±–æ—Ç–µ, –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º [PyTorch](https://pytorch.org/get-started/locally/), —ç—Ç–æ—Ç –º–∞—Å—Å–∏–≤ –º–æ–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Ñ–∞–π–ª torch.*Tensor.

–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ–ª–µ–∑–Ω—ã —Ç–∞–∫–∏–µ –ø–∞–∫–µ—Ç—ã, –∫–∞–∫ Pillow, OpenCV. –ê —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π PyTorch —Å–æ–∑–¥–∞–ª–∏ –ø–∞–∫–µ—Ç –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º torchvision, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ ImageNet, CIFAR10, MNIST –∏ —Ç. –¥., –∞ —Ç–∞–∫–∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∞ –∏–º–µ–Ω–Ω–æ: torchvision.datasets–∏ torch.utils.data.DataLoader.

–≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∑–Ω–∞—á–∏–º–æ–µ —É–¥–æ–±—Å—Ç–≤–æ –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è —à–∞–±–ª–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞.

–í —ç—Ç–æ–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö CIFAR10. –û–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∫–ª–∞—Å—Å—ã: ¬´—Å–∞–º–æ–ª–µ—Ç¬ª, ¬´–∞–≤—Ç–æ–º–æ–±–∏–ª—å¬ª, ¬´–ø—Ç–∏—Ü–∞¬ª, ¬´–∫–æ—à–∫–∞¬ª, ¬´–æ–ª–µ–Ω—å¬ª, ¬´—Å–æ–±–∞–∫–∞¬ª, ¬´–ª—è–≥—É—à–∫–∞¬ª, ¬´–ª–æ—à–∞–¥—å¬ª, ¬´–∫–æ—Ä–∞–±–ª—å¬ª, ¬´–≥—Ä—É–∑–æ–≤–∏–∫¬ª. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ CIFAR-10 –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä 3x32x32, —Ç–æ –µ—Å—Ç—å —Ç—Ä—ë—Ö–∫–∞–Ω–∞–ª—å–Ω—ã–µ —Ü–≤–µ—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–º 32x32 –ø–∏–∫—Å–µ–ª—è.

![cifar10](https://pytorch.org/tutorials/_static/img/cifar10.png)

---

## üìÅ –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –º–µ—Ç–æ–¥—ã

- –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ - [Ubuntu 22.04](https://help.ubuntu.ru/wiki/–∫–æ–º–∞–Ω–¥–Ω–∞—è_—Å—Ç—Ä–æ–∫–∞)
- –Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äì [python](https://www.python.org/).
- –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:
  -  [jupyter Notebook](https://jupyter.org/).
- –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
  - [matplotlib](https://matplotlib.org/)
  - [numpy](https://numpy.org/)
  - [PyTorch](https://pytorch.org/get-started/locally/)
- –î–∞—Ç–∞—Å–µ—Ç—ã:
  - —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç ["CIFAR-10"](https://www.cs.toronto.edu/~kriz/cifar.html)

---

## üß™ –ü—Ä–æ–≥—Ä–∞–º–º–∞ —Ä–∞–±–æ—Ç—ã 

---

### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã  

**–ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ [Jupyter-Hub](https://jupyter.org/hub) –ø–æ –∞–¥—Ä–µ—Å—É [Jupyter-Hub-–ò–ò–°–¢-–ù–ü–ò](http://195.133.13.56:8000/)**

**–° –ø–æ–º–æ—â—å—é —Ñ–∞–π–ª–æ–≤–æ–≥–æ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä–∞, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–æ–≥–æ —Å–ª–µ–≤–∞ –ø–µ—Ä–µ–π—Ç–∏ –≤ —Å–≤–æ–π –∫–∞—Ç–∞–ª–æ–≥ (–§–ò–û –∏ –≥–æ–¥), —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ä–∞–Ω–µ–µ (–¥–≤–æ–π–Ω—ã–º –Ω–∞–∂–∞—Ç–∏–µ–º –º—ã—à–∏)**

**–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –≤–∫–ª–∞–¥–∫—É —Å–∏–º–≤–æ–ª–æ–º +**

**–í—ã–±—Ä–∞—Ç—å —Ç–∏–ø –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–∏ -- Notebook**

**–°–æ—Ö—Ä–∞–Ω–∏—Ç—å / –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Ñ–∞–π–ª**

**–†–∞–±–æ—Ç–∞—Ç—å –≤ –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–µ –≤–∏–¥–∞**

![–í–ª–∞–¥–∫–∞ Notebook](../images/notebook_clear_window.png)

**–ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫**

```python
import torch
import torchvision
import torchvision.transforms as transforms
%matplotlib inline
```

---

### üß™ –ü–æ—Ä—è–¥–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

  1. üß™ –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ TorchVision –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è PILImage –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ `[0,1]`. –ú—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Ö –≤ —Ç–µ–Ω–∑–æ—Ä—ã –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ `[-1, 1]`.
```python
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

batch_size = 4

trainset = torchvision.datasets.CIFAR10(root='/home/jupyter/work/data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='/home/jupyter/work/data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```
  2. üß™ –ü—Ä–æ—Å–º–æ—Ç—Ä–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —É—á–µ–±–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
```python
import matplotlib.pyplot as plt
import numpy as np

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(trainloader)
images, labels = next(dataiter)

imshow(torchvision.utils.make_grid(images))
print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))
```
  3. üß™ –û–ø—Ä–µ–¥–µ–ª–∏–º —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
```python
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super().__init__()
        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html
        self.conv1 = nn.Conv2d(3, 6, 5)
        # https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        # Flattens the output of a multi-dimensional volume (e.g., a CONV or POOL layer) such that we can apply fully connected layers to it
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
device = torch.device('cpu')
net.to(device)
```
  4. üß™ –û–ø—Ä–µ–¥–µ–ª–∏–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
```python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```
  5. üß™ –û–±—É—á–∞–µ–º —Å–µ—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏–º –Ω–∞—à—É –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
```python
for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0

print('Finished Training')
PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)
```
  6. üß™ –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
```python
# –ü—Ä–µ–¥—Å–∫–∞–∂–µ–º –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞, –∫–æ—Ç–æ—Ä—É—é –≤—ã–¥–∞—Å—Ç –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å, –∏ —Å–≤–µ—Ä–∏–º –µ—ë —Å –∏—Å—Ç–∏–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º.
‚Ññ –ï—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–Ω–æ, –º—ã –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–∑–µ—Ü –≤ —Å–ø–∏—Å–æ–∫ –≤–µ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π.
dataiter = iter(testloader)
images, labels = next(dataiter)

# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))

# –ó–∞–≥—Ä—É–∑–∏–º –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞—à—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
# (–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∑–¥–µ—Å—å –Ω–µ –±—ã–ª–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º–∏, –º—ã —Å–¥–µ–ª–∞–ª–∏ —ç—Ç–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø—Ä–æ–∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å, –∫–∞–∫ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å)
net = Net()
net.load_state_dict(torch.load(PATH, weights_only=True))

# –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –¥—É–º–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –æ–± —ç—Ç–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
outputs = net(images)

# –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è 10 –∫–ª–∞—Å—Å–æ–≤.
# –ß–µ–º –≤—ã—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞, —Ç–µ–º –±–æ–ª—å—à–µ —Å–µ—Ç—å —Å–∫–ª–æ–Ω–Ω–∞ —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç —ç—Ç–æ–º—É –∫–ª–∞—Å—Å—É.
# –ü–æ–ª—É—á–∏–º –∏–Ω–¥–µ–∫—Å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–µ–π:

_, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'
                              for j in range(4)))

# –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Å–µ—Ç—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–æ –≤—Å–µ–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö
correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in testloader:
        images, labels = data
        # calculate outputs by running images through the network
        outputs = net(images)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')

# —Ç–æ–∂–µ —Å–∞–º–æ–µ, –Ω–æ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
correct_pred = {classname: 0 for classname in classes}
total_pred = {classname: 0 for classname in classes}

with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predictions = torch.max(outputs, 1)
        # collect the correct predictions for each class
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1

for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')
```

--- 

### üìå –ó–∞–¥–∞–Ω–∏—è

  - –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –Ω–∞ **1** _—à–∏—Ä–∏–Ω—É_ –≤–∞—à–µ–π —Å–µ—Ç–∏ (–∞—Ä–≥—É–º–µ–Ω—Ç ‚Ññ2 –ø–µ—Ä–≤–æ–≥–æ nn.Conv2d –∏ –∞—Ä–≥—É–º–µ–Ω—Ç ‚Ññ1 –≤—Ç–æ—Ä–æ–≥–æ nn.Conv2d ‚Äî –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ —á–∏—Å–ª–∞–º–∏) –∏ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ, –∫–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—Å—è —Ç–æ—á–Ω–æ—Å—Ç—å.

### üìå –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –æ—Ç—á–µ—Ç –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–º –ó–∞–¥–∞–Ω–∏–∏
